{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b93b45",
   "metadata": {},
   "source": [
    "Strava Cycling Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbd1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stravaio import strava_oauth2\n",
    "from stravaio import StravaIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import datetime\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84537746",
   "metadata": {},
   "source": [
    "TODO\n",
    " [ ] Add logging for all inserts made, use the athlete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b13e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CylcingStats:\n",
    "    def __init__(self, host=\"localhost\", db=\"CyclingStats\", usr=\"hank\", pwd=\"soccer18\"):\n",
    "        # Postgres db conn info\n",
    "        self.conn = None\n",
    "        self.host = host,\n",
    "        self.database = db,\n",
    "        self.user = usr,\n",
    "        self.password = pwd\n",
    "        self.client = None\n",
    "        \n",
    "        # Logging\n",
    "        self.verbose = False # for terminal logging (db logging is handled via the db)\n",
    "        self.insert_log_sql = 'INSERT INTO logs(who, status, source, action_type, db_table, db_column, db_value) VALUES(%s,%s,%s,%s,%s,%s,%s);'\n",
    "        self.insert_log_params = (None, None, None, None, None, None, None)\n",
    "        \n",
    "        # Activities dataframe\n",
    "        self.cols_activities = ['achievement_count', 'athlete', 'athlete_count', 'attribute_map', 'average_speed', 'average_watts', 'comment_count', 'commute', 'device_watts', 'discriminator', 'distance', 'elapsed_time', 'elev_high', 'elev_low', 'end_latlng', 'external_id', 'flagged', 'gear_id', 'has_kudoed', 'id', 'kilojoules',\n",
    " 'kudos_count', 'manual', 'map', 'max_speed', 'max_watts', 'moving_time', 'name', 'photo_count', 'private', 'start_date', 'start_date_local', 'start_latlng',\n",
    " 'swagger_types', 'timezone', 'total_elevation_gain', 'total_photo_count', 'trainer', 'type', 'upload_id', 'weighted_average_watts',  'workout_type']\n",
    "        \n",
    "        # Strava API stuff\n",
    "        self.api_calls_15min = 0\n",
    "        self.api_calls_1day = 0\n",
    "        self.api_call_lim_15min = 100\n",
    "        self.api_call_lim_1day = 1000\n",
    "        self.access_token = 'edc035ef398b08001156bbe78e5ca7c7b96afeb3' # TODO: this should be checked + refreshed auto\n",
    "        \n",
    "        # ATHLETE\n",
    "        self.athlete_id = None\n",
    "        self.athlete_name = ''\n",
    "        self.athlete = None \n",
    "        self.athlete_dict = None\n",
    "        \n",
    "        # ACTIVITIES\n",
    "        self.activities = [] # List of JSON for strava athletes activities\n",
    "        self.activities_df = None # Activities dataframe\n",
    "        self.activities_ids_master = [] # Master list of activities ids, parsed from the API\n",
    "        self.select_sql_activity_id = 'SELECT id from activities;' # Getting the Activities Ids from the DB to prevent dups\n",
    "        self.db_activity_ids = None # returns a 2d tuple\n",
    "        self.db_activity_ids_list = [] # the tuple is parsed to a 1d list\n",
    "        self.insert_sql = 'INSERT INTO Activities(achievement_count, athlete, athlete_count, attribute_map, average_speed, average_watts, comment_count, commute, device_watts, discriminator, distance, elapsed_time, elev_high, elev_low, end_latlng, external_id, flagged, gear_id, has_kudoed, id, kilojoules, kudos_count, manual, map, max_speed, max_watts, moving_time, name, photo_count, private, start_date, start_date_local, start_latlng, swagger_types, timezone, total_elevation_gain, total_photo_count, trainer, type, upload_id, weighted_average_watts, workout_type) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) RETURNING id;;'\n",
    "        self.insert_params = (None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n",
    "        \n",
    "        # STREAMS\n",
    "        self.streams = [] # Stream obj with to_dict which can be used to make a pandas df\n",
    "        self.streams_dict = None\n",
    "        self.streams_df = None # Streams dataframe, only ones that arent in the db\n",
    "        self.select_sql_stream_activity_id = 'select distinct cast(activity_id as bigint) from activities_streams;' # Getting the Streams Activities Ids from the DB to prevent dups\n",
    "        self.db_stream_activity_ids = None # returns a 2d tuple\n",
    "        self.db_stream_activity_ids_list = [] # the tuple is parsed to a 1d list\n",
    "        self.streams_missing = [] # Comparing activities_ids_master to _db_stream_activity_ids_list & popping them too\n",
    "        self.insert_activities_streams_sql = 'INSERT INTO Activities_Streams(time, distance, altitude, velocity_smooth, heartrate, cadence, watts, moving, grade_smooth, lat, lng, activity_id) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) returning db_id;'\n",
    "        self.insert_activities_streams_params = (None, None, None, None, None, None, None, None, None, None, None, None)\n",
    "        self.curr_activity_id = None # Streams have to be called 1 at a time\n",
    "        \n",
    "    #######################################################################################\n",
    "    # API Limit Handling & Logging\n",
    "    #######################################################################################      \n",
    "    # This is ultimately going to have to query a View\n",
    "    def CheckApiThreshold(self):\n",
    "        # Execute the CalculateApiHits15mins() & CalculateApiHits1day() functions on the db\n",
    "        self.conn = psycopg2.connect(host = \"localhost\", database = 'CyclingStats',\n",
    "                      user = 'postgres', password = 'soccer18')\n",
    "        with self.conn:\n",
    "            with self.conn.cursor() as curs:\n",
    "                curs.execute(\"select CalculateApiHits15mins();\")\n",
    "                self.api_calls_15min = curs.fetchall()\n",
    "                curs.execute(\"select CalculateApiHits1day();\")\n",
    "                self.api_calls_1day = curs.fetchall()\n",
    "                \n",
    "                if self.verbose: print(\"API Calls in past 15min: {0}\".format(self.api_calls_15min[0][0]))\n",
    "                if self.verbose: print(\"API Calls in past 1day: {0}\".format(self.api_calls_1day[0][0]))\n",
    "                \n",
    "        # Terminate the app if over the limit\n",
    "        if (self.api_calls_15min[0][0] >= self.api_call_lim_15min) | (self.api_calls_1day[0][0] >= self.api_call_lim_1day):\n",
    "            print(\"You exceeded the API limit for now, exiting.\")\n",
    "            self.exit()\n",
    "            \n",
    "        self.CloseDb()\n",
    "                \n",
    "    # Every interaction with the API & db should be logged, will introduce lookup tables & FKs eventually\n",
    "    def DbLog(self, _who, _status, _source, _action_type, _db_table, _db_column, _db_value, is_connected = False, _curs = None):\n",
    "        self.insert_log_params = (_who, _status, _source, _action_type, _db_table, _db_column, _db_value)\n",
    "        if is_connected == False:\n",
    "            self.conn = psycopg2.connect(host = \"localhost\", database = 'CyclingStats',\n",
    "                                  user = 'postgres', password = 'soccer18')\n",
    "            with self.conn:\n",
    "                with self.conn.cursor() as curs:\n",
    "                    \n",
    "                    curs.execute(self.insert_log_sql, self.insert_log_params)\n",
    "\n",
    "            self.CloseDb()\n",
    "        else:\n",
    "            _curs.execute(self.insert_log_sql, self.insert_log_params)\n",
    "        \n",
    "    #######################################################################################\n",
    "    # Master Methods\n",
    "    #######################################################################################\n",
    "    ## These just provide a one-click to do anything instead of having to call multiple methods\n",
    "    ## The only methods that should really be called after its stable\n",
    "    # Method that will ultimately try to do the full suite of connections, updates, and inserts\n",
    "    def OneClick(self):\n",
    "        if self.verbose == False:\n",
    "            self.verbose = True\n",
    "            self.CheckApiThreshold()\n",
    "            self.verbose = False\n",
    "            \n",
    "        # Connections\n",
    "        self.ConnectStravaApi()\n",
    "        # Athlete\n",
    "        self.GetAthlete()\n",
    "        # Activities\n",
    "        self.GetActivities()\n",
    "        self.ParseActivities()\n",
    "        self.GetDbActivityIds()\n",
    "        self.ParseDbActivityIds()\n",
    "        self.CompileMasterActivitiesIdList()\n",
    "        self.InsertActivities()\n",
    "        # Streams\n",
    "        self.GetDbStreamActivityIds()\n",
    "        self.ParseDbStreamActivityIds()\n",
    "        self.DetermineMissingStreams()\n",
    "        self.GetStreams() # This calls ParseStream() and InsertStreams()\n",
    "    \n",
    "    #######################################################################################\n",
    "    # Connections\n",
    "    #######################################################################################\n",
    "    \n",
    "    def RefreshAccessToken(self):\n",
    "        pass# TODO\n",
    "    \n",
    "    def ConnectStravaApi(self):\n",
    "        self.client = StravaIO(access_token = self.access_token) \n",
    "\n",
    "    # Don't use this until figure out how to pass vars into the params\n",
    "    def ConnectDb(self):\n",
    "        self.conn = psycopg2.connect(host=self.host, database=self.database,\n",
    "                                      user=self.user, password=self.password)\n",
    "\n",
    "    def CloseDb(self):\n",
    "        self.conn.close()\n",
    "\n",
    "    #######################################################################################\n",
    "    # Athlete\n",
    "    #######################################################################################       \n",
    "        \n",
    "    # Gets the current athlete\n",
    "    def GetAthlete(self):\n",
    "        self.CheckApiThreshold()\n",
    "        self.athlete = self.client.get_logged_in_athlete()\n",
    "        self.athlete_dict = self.athlete.to_dict()\n",
    "        self.ParseAthlete()\n",
    "        self.DbLog(self.athlete_name, 'Success', 'API', 'GET', 'athlete', '', str(self.athlete_id))\n",
    "        \n",
    "    def ParseAthlete(self):\n",
    "        self.athlete_name = self.athlete_dict['firstname'] + ' ' + self.athlete_dict['lastname']\n",
    "        self.athlete_id = self.athlete_dict['id']\n",
    "        \n",
    "    #######################################################################################\n",
    "    # Activities\n",
    "    #######################################################################################\n",
    "    \n",
    "    # Pulls a list of activities for the current athlete from the Strava API\n",
    "    def GetActivities(self):\n",
    "        self.CheckApiThreshold()\n",
    "        self.list_activities = self.client.get_logged_in_athlete_activities()\n",
    "        self.DbLog(self.athlete_name, 'Success', 'API', 'GET', 'activities', '', '')\n",
    "                   \n",
    "    # Parses the list of activities into a pandas dataframe\n",
    "    def ParseActivities(self):\n",
    "        # Parse out each activities and store each record in a list\n",
    "        for obj in self.list_activities:\n",
    "            record = [obj.achievement_count, obj.athlete, obj.athlete_count, obj.attribute_map, obj.average_speed, obj.average_watts, obj.comment_count, obj.commute, obj.device_watts, obj.discriminator, obj.distance, obj.elapsed_time, obj.elev_high, obj.elev_low, obj.end_latlng, obj.external_id, obj.flagged, obj.gear_id, obj.has_kudoed, obj.id, obj.kilojoules, obj.kudos_count, obj.manual, obj.map, obj.max_speed, obj.max_watts, obj.moving_time, obj.name, obj.photo_count, obj.private, obj.start_date, obj.start_date_local, obj.start_latlng, obj.swagger_types, obj.timezone, obj.total_elevation_gain, obj.total_photo_count, obj.trainer, obj.type, obj.upload_id, obj.weighted_average_watts, obj.workout_type]\n",
    " \n",
    "            self.activities.append(record)\n",
    "            \n",
    "        # Build a dataframe from the activities\n",
    "        self.activities_df = pd.DataFrame(self.activities, columns=self.cols_activities)\n",
    "    \n",
    "    # Pull Activity Ids from db to make sure dups arent inserted\n",
    "    def GetDbActivityIds(self):\n",
    "        self.conn = psycopg2.connect(host = \"localhost\", database = 'CyclingStats',\n",
    "                      user = 'postgres', password = 'soccer18')\n",
    "        with self.conn:\n",
    "            with self.conn.cursor() as curs:\n",
    "                curs.execute(self.select_sql_activity_id)\n",
    "                self.db_activity_ids = curs.fetchall()\n",
    "        \n",
    "        self.CloseDb()\n",
    "        self.DbLog(self.athlete_name, 'Success', 'DB', 'SELECT', 'activities', 'Id', '')\n",
    "    \n",
    "    # These are returned as a tuple, parsing them into a 1d list to compare against db Activity Ids \n",
    "    #to make sure dups aren't inserted\n",
    "    def ParseDbActivityIds(self): \n",
    "        for rec in self.db_activity_ids:\n",
    "             self.db_activity_ids_list.append(rec[0])                       \n",
    "        \n",
    "    def CompileMasterActivitiesIdList(self):\n",
    "        for record in self.activities_df.itertuples():\n",
    "            self.activities_ids_master.append(record.id)\n",
    "        \n",
    "    # Insert activities from the Strava API into the Postgres CyclingStats db\n",
    "    def InsertActivities(self):\n",
    "        self.CheckApiThreshold()\n",
    "        \n",
    "        self.conn = psycopg2.connect(host = \"localhost\", database = 'CyclingStats',\n",
    "                              user = 'postgres', password = 'soccer18')\n",
    "        with self.conn:\n",
    "            \n",
    "            with self.conn.cursor() as curs:\n",
    "                \n",
    "                # TODO: need to make sure at max __ records to not go over api limit\n",
    "                for record in self.activities_df.itertuples():\n",
    "                    \n",
    "                    # Make sure the Activity isnt already in the db\n",
    "                    if record.id not in self.db_activity_ids_list:\n",
    "                        self.insert_params = (record.achievement_count, str(record.athlete), record.athlete_count, str(record.attribute_map), record.average_speed, record.average_watts, record.comment_count, record.commute, str(record.device_watts), str(record.discriminator), record.distance, record.elapsed_time, record.elev_high, record.elev_low, str(record.end_latlng), str(record.external_id), record.flagged, str(record.gear_id), record.has_kudoed, record.id, record.kilojoules, record.kudos_count, record.manual, str(record.map), record.max_speed, record.max_watts, record.moving_time, str(record.name), record.photo_count, record.private, record.start_date, record.start_date_local, str(record.start_latlng), str(record.swagger_types), str(record.timezone), record.total_elevation_gain, record.total_photo_count, record.trainer, str(record.type), record.upload_id, record.weighted_average_watts, record.workout_type)\n",
    "                        curs.execute(self.insert_sql, self.insert_params)\n",
    "                        self.DbLog(self.athlete_name, 'Success', 'DB', 'INSERT', 'activities', 'id', record.id, True, curs)\n",
    "                        if self.verbose == True: print('Inserted Activity {0} successfully'.format(str(record.id)))\n",
    "                        self.insert_params = (None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n",
    "                    \n",
    "                    else:\n",
    "                        if self.verbose == True: print('Activity {0} already in the database'.format(str(record.id)))\n",
    "        \n",
    "        self.CloseDb()\n",
    "        \n",
    "    #######################################################################################\n",
    "    # Activity Streams\n",
    "    #######################################################################################\n",
    "    \n",
    "    # Pull Activity Ids from db to make sure dups arent inserted\n",
    "    def GetDbStreamActivityIds(self):\n",
    "        self.conn = psycopg2.connect(host = \"localhost\", database = 'CyclingStats',\n",
    "                      user = 'postgres', password = 'soccer18')\n",
    "        with self.conn:\n",
    "            with self.conn.cursor() as curs:\n",
    "                curs.execute(self.select_sql_stream_activity_id)\n",
    "                self.db_stream_activity_ids = curs.fetchall()\n",
    "        self.CloseDb()\n",
    "        self.DbLog(self.athlete_name, 'Success', 'DB', 'SELECT', 'streams', 'Activity_id', '')\n",
    "    \n",
    "    # These are returned as a tuple, parsing them into a 1d list to compare against db Stream Activity Ids \n",
    "    #to make sure dups aren't inserted\n",
    "    def ParseDbStreamActivityIds(self): \n",
    "        for rec in self.db_stream_activity_ids:\n",
    "             self.db_stream_activity_ids_list.append(rec[0])\n",
    "    \n",
    "    def DetermineMissingStreams(self):\n",
    "        for act_id in self.activities_ids_master:\n",
    "            if act_id not in self.db_stream_activity_ids_list:\n",
    "                self.streams_missing.append(act_id)\n",
    "    \n",
    "    # Pull a list of Streams based on activities_df.id\n",
    "    def GetStreams(self):\n",
    "        for act_id in self.streams_missing:\n",
    "            self.stream = self.client.get_activity_streams(act_id, athlete_id = self.athlete_id)\n",
    "            self.DbLog(self.athlete_name, 'Success', 'API', 'GET', 'Streams', '', '') \n",
    "            self.ParseStream(_activity_id = act_id)\n",
    "            self.InsertStreams()\n",
    "            \n",
    "            self.stream = None\n",
    "            self.streams_dict = None\n",
    "            self.streams_df = None\n",
    "            \n",
    "            #self.streams_missing.remove(act_id) # So can pick up where left off after 15 mins\n",
    "        \n",
    "    def ParseStream(self, _activity_id):\n",
    "        self.streams_dict = cs.stream.to_dict()\n",
    "        self.streams_df = pd.DataFrame(cs.streams_dict)\n",
    "        self.streams_df['activity_id'] = _activity_id\n",
    "        \n",
    "        if 'time' not in self.streams_df.columns: self.streams_df['time'] = ''\n",
    "        if 'distance' not in self.streams_df.columns: self.streams_df['distance'] = '-1'\n",
    "        if 'altitude' not in self.streams_df.columns: self.streams_df['altitude'] = '-1'\n",
    "        if 'velocity_smooth' not in self.streams_df.columns: self.streams_df['velocity_smooth'] = '-1'\n",
    "        if 'heartrate' not in self.streams_df.columns: self.streams_df['heartrate'] = '-1'\n",
    "        if 'cadence' not in self.streams_df.columns: self.streams_df['cadence'] = '-1'\n",
    "        if 'watts' not in self.streams_df.columns: self.streams_df['watts'] = '-1'\n",
    "        if 'moving' not in self.streams_df.columns: self.streams_df['moving'] = ''\n",
    "        if 'grade_smooth' not in self.streams_df.columns: self.streams_df['grade_smooth'] = '-1'\n",
    "        if 'lat' not in self.streams_df.columns: self.streams_df['lat'] = ''\n",
    "        if 'lng' not in self.streams_df.columns: self.streams_df['lng'] = ''\n",
    "    \n",
    "    def InsertStreams(self):      \n",
    "        self.conn = psycopg2.connect(host = \"localhost\", database = 'CyclingStats',\n",
    "                              user = 'postgres', password = 'soccer18')\n",
    "        with self.conn:\n",
    "            with self.conn.cursor() as curs:\n",
    "                for record in self.streams_df.itertuples():\n",
    "                    self.insert_activities_streams_params = (str(record.time), str(record.distance), str(record.altitude), str(record.velocity_smooth), str(record.heartrate), str(record.cadence), str(record.watts), str(record.moving), str(record.grade_smooth), str(record.lat), str(record.lng), str(record.activity_id))\n",
    "                    curs.execute(self.insert_activities_streams_sql, self.insert_activities_streams_params)\n",
    "                    \n",
    "                    self.curr_stream_id = curs.fetchone()[0]\n",
    "                    self.DbLog(self.athlete_name, 'Success', 'DB', 'INSERT', 'streams', 'db_id', self.curr_stream_id, True, _curs = curs)\n",
    "                    self.curr_stream_id = None\n",
    "                        \n",
    "                    # Reset the params, just in case\n",
    "                    self.insert_activities_streams_params = (None, None, None, None, None, None, None, None, None, None, None, None)\n",
    "                \n",
    "                if self.verbose == True: print('Inserted Activity Stream for Activity {0}.'.format(str(record.activity_id)))\n",
    "  \n",
    "        self.insert_activities_streams_params = (None, None, None, None, None, None, None, None, None, None, None, None)\n",
    "        self.CloseDb()\n",
    "    #######################################################################################\n",
    "    # UI \n",
    "    #######################################################################################\n",
    "    # Will be called by a button on the UI for Users to export out a listing of their activities by date\n",
    "    #def ExportActivitiesFromDb(self, start_date, end_date):\n",
    "        # Pull list of activities from db filtered on date\n",
    "        \n",
    "        # Store as dataframe\n",
    "        \n",
    "        # Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a2191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CylcingStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdbd129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Calls in past 15min: 0\n",
      "API Calls in past 1day: 0\n",
      "Fetched 30, the latests is on 2020-03-09 16:59:31+00:00\n",
      "Fetched 30, the latests is on 2020-06-12 16:11:46+00:00\n",
      "Fetched 30, the latests is on 2020-07-25 17:05:59+00:00\n",
      "Fetched 30, the latests is on 2020-12-20 16:53:14+00:00\n",
      "Fetched 30, the latests is on 2021-04-29 21:01:32+00:00\n",
      "Fetched 19, the latests is on 2021-06-25 20:32:41+00:00\n"
     ]
    }
   ],
   "source": [
    "cs.OneClick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573792f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
